{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eccf21c-b74c-4f39-acf9-f62605a4dba9",
   "metadata": {},
   "source": [
    "# å®éªŒå…­ å†³ç­–æ ‘åˆ†ç±»å™¨\n",
    "## 2210529 ç½—ç‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee9769-fbbe-4f53-894b-1c42361a0d99",
   "metadata": {},
   "source": [
    "## åŸºæœ¬è¦æ±‚\n",
    "\n",
    "åŸºäº Watermelon-train1æ•°æ®é›†ï¼ˆåªæœ‰ç¦»æ•£å±æ€§ï¼‰ï¼Œæ„é€ ID3å†³ç­–æ ‘ï¼›\n",
    "åŸºäºæ„é€ çš„ ID3 å†³ç­–æ ‘ï¼Œå¯¹æ•°æ®é›† Watermelon-test1è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç²¾åº¦ï¼›\n",
    "## ä¸­çº§è¦æ±‚\n",
    "\n",
    "å¯¹æ•°æ®é›†Watermelon-train2ï¼Œæ„é€ C4.5æˆ–è€…CARTå†³ç­–æ ‘ï¼Œè¦æ±‚å¯ä»¥å¤„ç†è¿ç»­å‹å±æ€§ï¼›\n",
    "å¯¹æµ‹è¯•é›†Watermelon-test2è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç²¾åº¦ï¼›\n",
    "## é«˜çº§è¦æ±‚\n",
    "ä½¿ç”¨ä»»æ„çš„å‰ªæç®—æ³•å¯¹æ„é€ çš„å†³ç­–æ ‘ï¼ˆåŸºæœ¬è¦æ±‚å’Œä¸­çº§è¦æ±‚æ„é€ çš„æ ‘ï¼‰è¿›è¡Œå‰ªæï¼Œè§‚å¯Ÿæµ‹è¯•é›†åˆçš„åˆ†ç±»ç²¾åº¦æ˜¯å¦æœ‰æå‡ï¼Œç»™å‡ºåˆ†æè¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458d7df-8162-499d-9e0a-98f35bfa7bbf",
   "metadata": {},
   "source": [
    "## ***åŸºæœ¬è¦æ±‚å®ç°***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f3062c-5fc6-4801-8e17-d5458c59cf21",
   "metadata": {},
   "source": [
    "### **åŠ è½½æ•°æ®**\n",
    "ä½¿ç”¨load_txtæ–¹æ³•ä»train1.scv ä¸­è¯»å…¥æ•°æ®ï¼Œå°†ç¦»æ•£çš„ç‰¹å¾å€¼ï¼ˆå¦‚â€œé’ç»¿â€â€œèœ·ç¼©â€ç­‰ï¼‰è½¬æ¢ä¸ºç´¢å¼•è¡¨ç¤ºï¼Œå°†ä¼šè¿”å›ä¸€ä¸ªNumPyæ•°ç»„ï¼Œæ•°ç»„çš„æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ ·æœ¬ã€‚\n",
    "è¾“å‡ºæ ¼å¼æ¯ä¸€è¡Œçš„æ ¼å¼æ˜¯ [ç¼–å·, è‰²æ³½ç´¢å¼•, æ ¹è’‚ç´¢å¼•, æ•²å£°ç´¢å¼•, çº¹ç†ç´¢å¼•, æ ‡ç­¾ç´¢å¼•]ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "019c8df4-0c9f-4b80-9ab6-eb8d1c74af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "feature_dict = {\"è‰²æ³½\": [\"é’ç»¿\", \"ä¹Œé»‘\", \"æµ…ç™½\"],\n",
    "                \"æ ¹è’‚\": [\"èœ·ç¼©\", \"ç¨èœ·\", \"ç¡¬æŒº\"],\n",
    "                \"æ•²å£°\": [\"æµŠå“\", \"æ²‰é—·\", \"æ¸…è„†\"],\n",
    "                \"çº¹ç†\": [\"æ¸…æ™°\", \"ç¨ç³Š\", \"æ¨¡ç³Š\"]\n",
    "                }\n",
    "lable_list = [\"å¦\", \"æ˜¯\"]\n",
    "feature_list = [\"è‰²æ³½\", \"æ ¹è’‚\", \"æ•²å£°\", \"çº¹ç†\"]\n",
    "\n",
    "def load_txt(path):\n",
    "    ans = []\n",
    "    with codecs.open(path, \"r\", \"GBK\") as f:\n",
    "        line = f.readline()  # è¯»å–è¡¨å¤´ï¼Œè·³è¿‡\n",
    "        line = f.readline()  # è¯»å–æ•°æ®ç¬¬ä¸€è¡Œ\n",
    "        while line:\n",
    "            d = line.rstrip(\"\\r\\n\").split(',')  # æŒ‰é€—å·åˆ†å‰²æ¯è¡Œæ•°æ®\n",
    "            re = []\n",
    "            re.append(int(d[0]))  # ç¬¬0åˆ—æ˜¯ç¼–å·ï¼Œä½œä¸ºè¾…åŠ©ä¿¡æ¯\n",
    "            re.append(feature_dict.get(\"è‰²æ³½\").index(d[1]))  # å°†â€œè‰²æ³½â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(feature_dict.get(\"æ ¹è’‚\").index(d[2]))  # å°†â€œæ ¹è’‚â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(feature_dict.get(\"æ•²å£°\").index(d[3]))  # å°†â€œæ•²å£°â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(feature_dict.get(\"çº¹ç†\").index(d[4]))  # å°†â€œçº¹ç†â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(lable_list.index(d[-1]))  # æœ€åä¸€åˆ—æ˜¯æ ‡ç­¾ï¼ˆâ€œæ˜¯â€æˆ–â€œå¦â€ï¼‰ï¼Œæ˜ å°„ä¸ºç´¢å¼•\n",
    "            ans.append(np.array(re))  # å­˜å‚¨ä¸ºNumPyæ•°ç»„\n",
    "            line = f.readline()  # ç»§ç»­è¯»å–ä¸‹ä¸€è¡Œ\n",
    "    return np.array(ans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde1089-141c-45dc-8a83-73738b09be5d",
   "metadata": {},
   "source": [
    "### **å®šä¹‰ä¿¡æ¯ç†µä¸ä¿¡æ¯å¢ç›Šçš„è®¡ç®—**\n",
    "\n",
    "åˆ†åˆ«ä½¿ç”¨entå’Œgainå‡½æ•°ã€‚\n",
    "\n",
    "#### ä¿¡æ¯ç†µçš„è®¡ç®—:entå‡½æ•°\n",
    "$$H(D)=-\\sum_{k=1}^Kp_k\\log_2p_k$$\n",
    "è¾“å…¥ï¼šç±»åˆ«æ ‡ç­¾æ•°ç»„Dï¼ˆå¦‚[0, 1, 1, 0]ï¼‰ã€‚\n",
    "è¾“å‡ºï¼šæ•°æ®é›†çš„ç†µï¼Œè¡¨ç¤ºç±»åˆ«åˆ†å¸ƒçš„ä¸ç¡®å®šæ€§ã€‚\n",
    "\n",
    "\n",
    "#### ä¿¡æ¯å¢ç›Šçš„è®¡ç®—gainå‡½æ•°\n",
    "$$Gain(D,A)=H(D)-\\sum_{v\\in A}\\frac{|D_v|}{|D|}H(D_v)$$\n",
    "è¾“å…¥ï¼šæ ·æœ¬é›†Xï¼Œç±»åˆ«æ ‡ç­¾Yï¼Œå±æ€§ç´¢å¼•attrã€‚\n",
    "è¾“å‡ºï¼šåœ¨è¯¥å±æ€§ä¸Šçš„ä¿¡æ¯å¢ç›Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317d748d-98a9-445d-bb7a-16c935c01563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent(D):\n",
    "    s = 0\n",
    "    for k in set(D):\n",
    "        p_k = np.sum(np.where(D == k, 1, 0)) / np.shape(D)[0]  # æ¯ä¸ªç±»åˆ«kçš„æ¦‚ç‡\n",
    "        if p_k == 0:\n",
    "            continue  # æ¦‚ç‡ä¸º0æ—¶ï¼Œç†µè´¡çŒ®ä¸º0\n",
    "        s += p_k * np.log2(p_k)  # è®¡ç®—ç†µå…¬å¼\n",
    "    return -s\n",
    "\n",
    "def gain(X, Y, attr):\n",
    "    x_attr_col = X[:, attr]  # è·å–å½“å‰å±æ€§åˆ—\n",
    "    ent_Dv = []  # å­é›†çš„ç†µ\n",
    "    weight_Dv = []  # å­é›†çš„æƒé‡\n",
    "    for x_v in set(x_attr_col):  # éå†å±æ€§çš„æ‰€æœ‰å–å€¼\n",
    "        index_x_equal_v = np.where(x_attr_col == x_v)\n",
    "        y_x_equal_v = Y[index_x_equal_v]  # å¯¹åº”çš„å­é›†æ ‡ç­¾\n",
    "        ent_Dv.append(ent(y_x_equal_v))  # å­é›†çš„ç†µ\n",
    "        weight_Dv.append(np.shape(y_x_equal_v)[0] / np.shape(Y)[0])  # å­é›†æƒé‡\n",
    "    return ent(Y) - np.sum(np.array(ent_Dv) * np.array(weight_Dv))  # ä¿¡æ¯å¢ç›Šå…¬å¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a2a61-b28c-4a9c-a239-092fdbcdcf20",
   "metadata": {},
   "source": [
    "### **å®šä¹‰å†³ç­–æ ‘èŠ‚ç‚¹ï¼šNode**\n",
    "\n",
    "å¦‚æœattr == -1ï¼Œè¡¨ç¤ºè¿™æ˜¯å¶èŠ‚ç‚¹ï¼Œlabelå­˜å‚¨ç±»åˆ«ã€‚\n",
    "å¦‚æœlabel == Ï€ï¼Œè¡¨ç¤ºéå¶èŠ‚ç‚¹ï¼Œattrå­˜å‚¨åˆ’åˆ†å±æ€§ã€‚\n",
    "childrenå­˜å‚¨å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff941116-3866-46c8-bdd0-59646cc08fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attr, label, v):\n",
    "        self.attr = attr  # èŠ‚ç‚¹åˆ’åˆ†çš„å±æ€§ç´¢å¼•ï¼ˆ-1 è¡¨ç¤ºå¶èŠ‚ç‚¹ï¼‰\n",
    "        self.label = label  # èŠ‚ç‚¹çš„ç±»åˆ«æ ‡ç­¾ï¼ˆÏ€ è¡¨ç¤ºéå¶èŠ‚ç‚¹ï¼‰\n",
    "        self.attr_v = v  # çˆ¶èŠ‚ç‚¹åˆ’åˆ†å±æ€§çš„å€¼ï¼ˆä»…å¯¹å­èŠ‚ç‚¹æœ‰æ„ä¹‰ï¼‰\n",
    "        self.children = []  # å­èŠ‚ç‚¹åˆ—è¡¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090fa134-9cdd-400e-8ea9-7c6b7f833886",
   "metadata": {},
   "source": [
    "### **å®šä¹‰å‡½æ•°éªŒè¯å±æ€§ä¸Šçš„å€¼æ˜¯å¦ç›¸åŒ** \n",
    "is_same_on_attr é€šå¸¸ç”¨äºå†³ç­–æ ‘æ„å»ºçš„ç‰¹æ®Šæƒ…å†µå¤„ç†ï¼š\n",
    "\n",
    "æ£€æŸ¥æ ·æœ¬æ˜¯å¦æ— æ³•åˆ’åˆ†ï¼š\n",
    "\n",
    "åœ¨å†³ç­–æ ‘é€’å½’è¿‡ç¨‹ä¸­ï¼Œå¦‚æœæ ·æœ¬çš„æ‰€æœ‰å±æ€§å€¼åœ¨æŒ‡å®šçš„å±æ€§é›†åˆä¸Šå®Œå…¨ç›¸åŒï¼Œåˆ™è¯´æ˜æ— æ³•é€šè¿‡è¿™äº›å±æ€§è¿›ä¸€æ­¥åˆ’åˆ†ã€‚\n",
    "ç»ˆæ­¢é€’å½’ï¼Œç”Ÿæˆå¶èŠ‚ç‚¹ï¼š\n",
    "\n",
    "å½“æ‰€æœ‰æ ·æœ¬çš„å±æ€§å€¼å®Œå…¨ä¸€è‡´æ—¶ï¼Œå†³ç­–æ ‘ä¼šé€‰æ‹©ç›´æ¥ç”Ÿæˆå¶èŠ‚ç‚¹ï¼Œè€Œä¸å†ç»§ç»­åˆ†è£‚ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dcf0c60-d709-4d9d-b5bb-9f31425cbb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_on_attr(X, attrs):#éªŒè¯å±æ€§ä¸Šçš„å€¼æ˜¯å¦å‡ç›¸åŒ\n",
    "    X_a = X[:, attrs]\n",
    "    target = X_a[0]\n",
    "    for r in range(X_a.shape[0]):\n",
    "        row = X_a[r]\n",
    "        if (row != target).any():\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081da260-f075-4945-8759-c9c424bc89d5",
   "metadata": {},
   "source": [
    "### **æ„å»ºå†³ç­–æ ‘**ï¼ˆå‡½æ•°dicision_tree_initï¼‰\n",
    "é€’å½’åœ°æ„é€ å†³ç­–æ ‘ï¼š\n",
    "\n",
    "æ£€æŸ¥æ˜¯å¦å¯ä»¥ç›´æ¥ç”Ÿæˆå¶èŠ‚ç‚¹ã€‚\n",
    "\n",
    "é€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„å±æ€§ä½œä¸ºåˆ’åˆ†ä¾æ®ã€‚\n",
    "\n",
    "å¯¹äºæ¯ä¸ªå–å€¼ç”Ÿæˆå­èŠ‚ç‚¹ï¼Œå¹¶é€’å½’è°ƒç”¨è‡ªèº«ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c64ca86b-ae85-43b8-bc2b-f7326ea3d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicision_tree_init(X, Y, attrs, root, purity_cal):\n",
    "    # é€’å½’åŸº\n",
    "    if len(set(Y)) == 1:\n",
    "        root.attr = np.pi\n",
    "        root.label = Y[0]\n",
    "        return None\n",
    "\n",
    "    if len(attrs) == 0 or is_same_on_attr(X, attrs):\n",
    "        root.attr = np.pi\n",
    "        # Y ä¸­å‡ºç°æ¬¡æ•°æœ€å¤šçš„labelè®¾å®šä¸ºnodeçš„label\n",
    "        root.label = np.argmax(np.bincount(Y))\n",
    "        return None\n",
    "\n",
    "    # è®¡ç®—æ¯ä¸ªattrçš„åˆ’åˆ†æ”¶ç›Š\n",
    "    purity_attrs = []\n",
    "    for i, a in enumerate(attrs):\n",
    "        p = purity_cal(X, Y, a)\n",
    "        purity_attrs.append(p)\n",
    "    #print(purity_attrs)\n",
    "    chosen_index = purity_attrs.index(max(purity_attrs))\n",
    "    chosen_attr = attrs[chosen_index]\n",
    "\n",
    "    root.attr = chosen_attr\n",
    "    root.label = np.pi\n",
    "\n",
    "    del attrs[chosen_index]\n",
    "\n",
    "    x_attr_col = X[:, chosen_attr]\n",
    "    # ç¦»æ•£æ•°æ®å¤„ç†\n",
    "    for x_v in set(X[:, chosen_attr]):\n",
    "        n = Node(-1, -1, x_v)\n",
    "        root.children.append(n)\n",
    "        # ä¸å¯èƒ½Dv empty è¦æ˜¯emptyå‹æ ¹ä¸ä¼šåœ¨seté‡Œ\n",
    "        # é€‰å‡º X[attr] == x_vçš„è¡Œ\n",
    "\n",
    "        index_x_equal_v = np.where(x_attr_col == x_v)\n",
    "        X_x_equal_v = X[index_x_equal_v]\n",
    "        Y_x_equal_v = Y[index_x_equal_v]\n",
    "        dicision_tree_init(X_x_equal_v, Y_x_equal_v, attrs, n, purity_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d80564-884d-438f-af7d-ca029d6e3179",
   "metadata": {},
   "source": [
    "### **åŸºäºæ„å»ºçš„å†³ç­–æ ‘è¿›è¡Œé¢„æµ‹** å†³ç­–æ ‘é¢„æµ‹ï¼šdicision_tree_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27385a2b-5687-4cf7-a818-c6b22391d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicision_tree_predict(x, tree_root):\n",
    "    if tree_root.label != np.pi:  # å¦‚æœæ˜¯å¶èŠ‚ç‚¹ï¼Œè¿”å›ç±»åˆ«\n",
    "        return tree_root.label\n",
    "    for child in tree_root.children:  # éå†å­èŠ‚ç‚¹ï¼Œæ‰¾åˆ°åŒ¹é…çš„åˆ†æ”¯\n",
    "        if child.attr_v == x[tree_root.attr]:\n",
    "            return dicision_tree_predict(x, child)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec302df-3a5b-4567-b7db-9b99e343407a",
   "metadata": {},
   "source": [
    "æœ€ååœ¨ä¸»å‡½æ•°ä¸­è¿›è¡Œå†³ç­–æ ‘çš„æ„å»ºå’ŒåŸºäºå…¶è¿›è¡Œé¢„æµ‹ï¼Œæœ€åå†è®¡ç®—åˆ†ç±»å‡†ç¡®åº¦ï¼š\n",
    "å…·ä½“è¿‡ç¨‹æ˜¯ï¼›\n",
    "\n",
    "åŠ è½½è®­ç»ƒé›†ä¸æµ‹è¯•é›†ã€‚\n",
    "\n",
    "æ„å»ºID3å†³ç­–æ ‘å¹¶å­˜å‚¨åœ¨æ ¹èŠ‚ç‚¹rã€‚\n",
    "\n",
    "ä½¿ç”¨æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è®¡ç®—åˆ†ç±»ç²¾åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4662cf55-0d41-4a81-8f61-fdf641b1e0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ans = load_txt(\"Watermelon-train1.csv\")\n",
    "    X_train = ans[:, 1: -1]\n",
    "    Y_train = ans[:, -1].astype(np.int64)\n",
    "    test_data = load_txt(\"Watermelon-test1.csv\")\n",
    "    X_test = test_data[:, 1:-1]\n",
    "    Y_test = test_data[:, -1].astype(np.int64)\n",
    "    r = Node(-1, -1, -1)\n",
    "    attrs = [0, 1, 2, 3]\n",
    "    dicision_tree_init(X_train, Y_train, attrs, r, gain)\n",
    "    y_predict = [dicision_tree_predict(x, r) for x in X_test]\n",
    "    accuracy = sum(1 for y_true, y_pred in zip(Y_test, y_predict) if y_true == y_pred) / len(Y_test)\n",
    "    print('accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75675b67-7242-4f35-8e33-d701b52242cc",
   "metadata": {},
   "source": [
    "åˆ†ç±»ç²¾åº¦ä¸º0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e35e8c-249a-47e5-acca-dda378210781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "feature_dict = {\"è‰²æ³½\": [\"é’ç»¿\", \"ä¹Œé»‘\", \"æµ…ç™½\"],\n",
    "                \"æ ¹è’‚\": [\"èœ·ç¼©\", \"ç¨èœ·\", \"ç¡¬æŒº\"],\n",
    "                \"æ•²å£°\": [\"æµŠå“\", \"æ²‰é—·\", \"æ¸…è„†\"],\n",
    "                \"çº¹ç†\": [\"æ¸…æ™°\", \"ç¨ç³Š\", \"æ¨¡ç³Š\"]\n",
    "                }\n",
    "lable_list = [\"å¦\", \"æ˜¯\"]\n",
    "feature_list = [\"è‰²æ³½\", \"æ ¹è’‚\", \"æ•²å£°\", \"çº¹ç†\"]\n",
    "\n",
    "def load_txt(path):\n",
    "    ans = []\n",
    "    with codecs.open(path, \"r\", \"GBK\") as f:\n",
    "        line = f.readline()  # è¯»å–è¡¨å¤´ï¼Œè·³è¿‡\n",
    "        line = f.readline()  # è¯»å–æ•°æ®ç¬¬ä¸€è¡Œ\n",
    "        while line:\n",
    "            d = line.rstrip(\"\\r\\n\").split(',')  # æŒ‰é€—å·åˆ†å‰²æ¯è¡Œæ•°æ®\n",
    "            re = []\n",
    "            re.append(int(d[0]))  # ç¬¬0åˆ—æ˜¯ç¼–å·ï¼Œä½œä¸ºè¾…åŠ©ä¿¡æ¯\n",
    "            re.append(feature_dict.get(\"è‰²æ³½\").index(d[1]))  # å°†â€œè‰²æ³½â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(feature_dict.get(\"æ ¹è’‚\").index(d[2]))  # å°†â€œæ ¹è’‚â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(feature_dict.get(\"æ•²å£°\").index(d[3]))  # å°†â€œæ•²å£°â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(feature_dict.get(\"çº¹ç†\").index(d[4]))  # å°†â€œçº¹ç†â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(lable_list.index(d[-1]))  # æœ€åä¸€åˆ—æ˜¯æ ‡ç­¾ï¼ˆâ€œæ˜¯â€æˆ–â€œå¦â€ï¼‰ï¼Œæ˜ å°„ä¸ºç´¢å¼•\n",
    "            ans.append(np.array(re))  # å­˜å‚¨ä¸ºNumPyæ•°ç»„\n",
    "            line = f.readline()  # ç»§ç»­è¯»å–ä¸‹ä¸€è¡Œ\n",
    "    return np.array(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed9bf63-0ce5-44a8-94a2-b50890cfb618",
   "metadata": {},
   "source": [
    "## ***ä¸­çº§è¦æ±‚å®ç°ï¼ˆå®ç°CARTç®—æ³•èƒ½å¤Ÿå¤„ç†è¿ç»­å‹ç‰¹å¾ï¼‰***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6466b987-e911-4505-8b56-1dfdf0119445",
   "metadata": {},
   "source": [
    "#### è§‚å¯Ÿæ•°æ®é›†2å¯çŸ¥ï¼Œå¤šäº†è¿ç»­å‹çš„å±æ€§ï¼šå¯†åº¦ï¼Œå› æ­¤å®éªŒéœ€è¦é¦–å…ˆå†æ¬¡è§‚å¯Ÿä¸€ä¸‹æ•°æ®é›†å±æ€§ç»„æˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96ed9336-f4bf-4974-ab58-134a8a7275a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.     0.     0.     0.     0.     0.697  1.   ]\n",
      " [ 2.     1.     0.     1.     0.     0.774  1.   ]\n",
      " [ 3.     1.     0.     0.     0.     0.634  1.   ]\n",
      " [ 4.     0.     0.     1.     0.     0.608  1.   ]\n",
      " [ 5.     2.     0.     0.     0.     0.556  1.   ]\n",
      " [ 6.     0.     1.     0.     0.     0.403  1.   ]\n",
      " [ 7.     1.     1.     0.     1.     0.481  1.   ]\n",
      " [ 8.     1.     1.     0.     0.     0.437  1.   ]\n",
      " [ 9.     1.     1.     1.     1.     0.666  0.   ]\n",
      " [10.     0.     2.     2.     0.     0.243  0.   ]\n",
      " [11.     2.     2.     2.     2.     0.245  0.   ]\n",
      " [12.     2.     0.     0.     2.     0.343  0.   ]\n",
      " [13.     0.     1.     0.     1.     0.639  0.   ]\n",
      " [14.     2.     1.     1.     1.     0.657  0.   ]\n",
      " [15.     1.     1.     0.     0.     0.36   0.   ]\n",
      " [16.     2.     0.     0.     2.     0.593  0.   ]\n",
      " [17.     0.     0.     1.     1.     0.719  0.   ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "\n",
    "feature_dict = {\n",
    "    \"è‰²æ³½\": [\"é’ç»¿\", \"ä¹Œé»‘\", \"æµ…ç™½\"],\n",
    "    \"æ ¹è’‚\": [\"èœ·ç¼©\", \"ç¨èœ·\", \"ç¡¬æŒº\"],\n",
    "    \"æ•²å£°\": [\"æµŠå“\", \"æ²‰é—·\", \"æ¸…è„†\"],\n",
    "    \"çº¹ç†\": [\"æ¸…æ™°\", \"ç¨ç³Š\", \"æ¨¡ç³Š\"]\n",
    "}\n",
    "lable_list = [\"å¦\", \"æ˜¯\"]#æ˜¯å¦æ˜¯â€œå¥½ç“œ,å±æ€§åä¸ºå¥½ç“œâ€\n",
    "feature_list = [\"è‰²æ³½\", \"æ ¹è’‚\", \"æ•²å£°\", \"çº¹ç†\", \"å¯†åº¦\"]  # åŠ å…¥æ–°çš„è¿ç»­å‹ç‰¹å¾â€œå¯†åº¦â€\n",
    "\n",
    "def load_txt(path):\n",
    "    ans = []\n",
    "    with codecs.open(path, \"r\", \"GBK\") as f:\n",
    "        line = f.readline()  # è¯»å–è¡¨å¤´ï¼Œè·³è¿‡\n",
    "        line = f.readline()  # è¯»å–æ•°æ®ç¬¬ä¸€è¡Œ\n",
    "        while line:\n",
    "            d = line.rstrip(\"\\r\\n\").split(',')  # æŒ‰é€—å·åˆ†å‰²æ¯è¡Œæ•°æ®\n",
    "            re = []\n",
    "            re.append(int(d[0]))  # ç¬¬0åˆ—æ˜¯ç¼–å·ï¼Œä½œä¸ºè¾…åŠ©ä¿¡æ¯\n",
    "            re.append(feature_dict.get(\"è‰²æ³½\").index(d[1]))  # å°†â€œè‰²æ³½â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(feature_dict.get(\"æ ¹è’‚\").index(d[2]))  # å°†â€œæ ¹è’‚â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(feature_dict.get(\"æ•²å£°\").index(d[3]))  # å°†â€œæ•²å£°â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(feature_dict.get(\"çº¹ç†\").index(d[4]))  # å°†â€œçº¹ç†â€å±æ€§æ˜ å°„ä¸ºç´¢å¼•\n",
    "            re.append(float(d[5]))  # ç¬¬5åˆ—æ˜¯è¿ç»­å‹å˜é‡â€œå¯†åº¦â€ï¼Œä»¥æµ®ç‚¹æ•°å½¢å¼è¯»å–\n",
    "            re.append(lable_list.index(d[-1]))  # æœ€åä¸€åˆ—æ˜¯æ ‡ç­¾ï¼ˆâ€œæ˜¯â€æˆ–â€œå¦â€ï¼‰ï¼Œæ˜ å°„ä¸ºç´¢å¼•\n",
    "            ans.append(np.array(re))  # å­˜å‚¨ä¸ºNumPyæ•°ç»„\n",
    "            line = f.readline()  # ç»§ç»­è¯»å–ä¸‹ä¸€è¡Œ\n",
    "    return np.array(ans, dtype=np.float64)  # æŒ‡å®šè¿”å›çš„æ•°ç»„ç±»å‹ä¸ºfloat64\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = load_txt(\"Watermelon-train2.csv\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa51bd0-3210-412f-81fc-0ee00139b385",
   "metadata": {},
   "source": [
    "### å¯ä»¥çœ‹åˆ°å¤šäº†ä¸€ä¸ªå±æ€§åˆ—ä¸ºå¯†åº¦ï¼Œæ˜¯ä¸€ä¸ªè¿ç»­å˜é‡ï¼Œåé¢æˆ‘ä»¬å°†åˆ©ç”¨CARTç®—æ³•ä½¿ç”¨äºŒå…ƒåˆ‡åˆ†çš„æ–¹æ³•æ¥å¤„ç†è¿ç»­å˜é‡å¯†åº¦ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d790ac5-333c-44c7-a81f-2cc7c25e8225",
   "metadata": {},
   "source": [
    "### **æ•°æ®é›†çš„è¯»å–**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cfdcd09-1497-4905-9594-bf1849b37bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train2_dataset=pd.read_csv(\"Watermelon-train2.csv\",encoding='GBK')\n",
    "test2_dataset=pd.read_csv(\"Watermelon-test2.csv\",encoding='GBK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303d3fb-0a0c-4cfb-a460-64840c96bf97",
   "metadata": {},
   "source": [
    "### **åŸºå°¼æŒ‡æ•°çš„è®¡ç®—å®ç°ï¼Œä»¥åŠåŸºäºäºŒåˆ†æ–¹æ³•å¯»æ‰¾ç»­å‹ç‰¹å¾ï¼›å¯†åº¦çš„æœ€ä½³åˆ†å‰²ç‚¹**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e8318c-ba13-46ab-9ffc-dbfb77b36a99",
   "metadata": {},
   "source": [
    "#### æ³¨æ„æ˜¯/å¦åˆ—å±æ€§åä¸ºâ€œå¥½ç“œâ€ï¼Œä¸‹é¢å°†è®¡ç®—CARTç®—æ³•å¯¹åº”çš„åŸºå°¼ç³»æ•°,å¯¹äºCkï¼šï¼ˆğ·ä¸­å±äºç¬¬ğ‘˜ç±»çš„æ ·æœ¬å­é›†ï¼Œå¤§Kæ˜¯ç±»çš„ä¸ªæ•°ï¼‰å…¬å¼ï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1011496-d5b1-4c3e-a3da-7e5cef028814",
   "metadata": {},
   "source": [
    "$$Gini(D)=1-\\sum_{k=1}^K\\left(\\frac{|C_k|}{|D|}\\right)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75174eb0-bd56-4292-9057-57a75f7bd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—Gini æŒ‡æ•°\n",
    "def caculate_GINI(data):\n",
    "    # è®¡ç®—ç›®æ ‡åˆ—ä¸­æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡\n",
    "    class_probs = data['å¥½ç“œ'].value_counts(normalize=True)\n",
    "    # è®¡ç®— Gini æŒ‡æ•°\n",
    "    gini_index = 1 - sum([p ** 2 for p in class_probs])\n",
    "    return gini_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a951b14-e030-4b97-aa08-c94a5fa575b4",
   "metadata": {},
   "source": [
    "compute_gini_for_split å‡½æ•°æ˜¯è®¡ç®—ç‰¹å®šç‰¹å¾å¯¹äºæ•°æ®é›†åˆ†å‰²åçš„åŠ æƒ Gini æŒ‡æ•°çš„å‡½æ•°ã€‚å®ƒé€šè¿‡éå†ç‰¹å¾çš„æ‰€æœ‰å¯èƒ½å–å€¼ï¼Œå°†æ•°æ®é›†åˆ†å‰²ä¸ºå­é›†å¹¶è®¡ç®—åŠ æƒ Giniï¼Œä»è€Œå¸®åŠ©å†³ç­–æ ‘ç®—æ³•é€‰æ‹©æœ€ä¼˜çš„åˆ†å‰²ç‰¹å¾ã€‚è¿™é‡Œä½¿ç”¨å¯ä»¥åˆ©ç”¨ groupby æ“ä½œï¼ŒåŒæ—¶è®¡ç®—åŠ æƒ Gini çš„è¿‡ç¨‹ä¹Ÿå¯ä»¥ç®€åŒ–ã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥å¯¹æ•°æ®è¿›è¡Œåˆ†ç»„ï¼Œå¹¶è®¡ç®—æ¯ä¸ªç»„çš„ Gini å€¼ï¼Œæœ€åæ ¹æ®æ¯ä¸ªç»„çš„æ¯”ä¾‹è®¡ç®—åŠ æƒ Giniã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a9a97ed-d179-446d-847a-247dc2bc7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—ç‰¹å®šç‰¹å¾çš„ Gini åˆ†è£‚æŒ‡æ•°\n",
    "def calculate_GINI_for_split(data, feature):\n",
    "    # ä½¿ç”¨groupbyåˆ†ç»„ï¼Œå¹¶è®¡ç®—æ¯ä¸ªç»„çš„Gini\n",
    "    weighted_gini = data.groupby(feature).apply(lambda subset: compute_gini_index(subset)).mul(\n",
    "        data.groupby(feature).size() / len(data)\n",
    "    ).sum()\n",
    "\n",
    "    return weighted_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12215b-8cc7-47fc-88d2-d9c211e51d3a",
   "metadata": {},
   "source": [
    "å¯¹äºæ¯ä¸ªç‰¹å¾ï¼š\n",
    "\n",
    "æŒ‰ç…§ç‰¹å¾å€¼çš„å¤§å°è¿›è¡Œæ’åºã€‚\n",
    "\n",
    "è®¡ç®—ç›¸é‚»ä¸¤ä¸ªå€¼ä¹‹é—´çš„ä¸­ç‚¹ï¼Œä½œä¸ºå¯èƒ½çš„åˆ†å‰²ç‚¹ã€‚\n",
    "\n",
    "å¯¹äºæ¯ä¸ªåˆ†å‰²ç‚¹ï¼š\n",
    "\n",
    "å°†æ•°æ®é›†æ ¹æ®åˆ†å‰²ç‚¹åˆ’åˆ†ä¸ºå·¦å­é›†å’Œå³å­é›†ã€‚\n",
    "\n",
    "è®¡ç®—å·¦å­é›†å’Œå³å­é›†çš„ Gini æŒ‡æ•°ã€‚\n",
    "\n",
    "è®¡ç®—åŠ æƒ Gini æŒ‡æ•°ã€‚\n",
    "\n",
    "é€‰æ‹©åŠ æƒ Gini æŒ‡æ•°æœ€å°çš„åˆ†å‰²ç‚¹ï¼Œä½œä¸ºæœ€ä½³åˆ†å‰²ç‚¹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f36c13-0df2-4540-a934-ac1fecee6dc1",
   "metadata": {},
   "source": [
    "åœ¨æ‰¾åˆ°å¯èƒ½çš„åˆ†å‰²ç‚¹ä¹‹åï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åˆ†æˆä¸¤ä¸ªå­é›† (å·¦å­é›†å’Œå³å­é›†)ã€‚æ¯ä¸ªå­é›†çš„ Gini æŒ‡æ•°å¯\n",
    "ä»¥å•ç‹¬è®¡ç®—ï¼Œç„¶ååŠ æƒå¹³å‡ï¼Œä»¥å¾—åˆ°æ•´ä¸ªåˆ†å‰²ç‚¹çš„åŠ æƒ Gini æŒ‡æ•°ã€‚\n",
    "å‡è®¾åœ¨æŸä¸ªåˆ†å‰²ç‚¹ï¼Œæ•°æ®é›†$D$è¢«åˆ’åˆ†ä¸ºä¸¤ä¸ªå­é›†$D_\\mathrm{leff}$å’Œ$D_\\mathrm{right}$,å®ƒä»¬çš„å¤§å°åˆ†åˆ«ä¸º$n_\\mathrm{left}$å’Œ$n_\\mathrm{right}$\n",
    ",ä¸”æ€»æ•°æ®é›†å¤§å°ä¸º$n$,åˆ™åŠ æƒ Gini æŒ‡æ•°è®¡ç®—å…¬å¼ä¸ºï¼š\n",
    "$$Gini_{{\\mathrm{split}}}=\\frac{n_{{\\mathrm{left}}}}{n}\\cdot Gini(D_{{\\mathrm{left}}})+\\frac{n_{{\\mathrm{right}}}}{n}\\cdot Gini(D_{{\\mathrm{right}}})$$\n",
    "\n",
    "å³ï¼š\n",
    "\n",
    "1. è®¡ç®—å·¦å­é›†çš„ Gini æŒ‡æ•°$Gini(D_\\mathrm{left})$å’Œå³å­é›†çš„ Gini æŒ‡æ•°$Gini(D_\\mathrm{right})$ã€‚\n",
    "2. æ ¹æ®å·¦å­é›†å’Œå³å­é›†çš„æ ·æœ¬æ•°é‡ï¼Œè®¡ç®—åŠ æƒå¹³å‡çš„ Gini æŒ‡æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "753ab44d-4388-40f0-ad2a-fab7692d7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºäº Gini æŒ‡æ•°ï¼Œæ‰¾åˆ°è¿ç»­å‹ç‰¹å¾çš„æœ€ä½³åˆ†å‰²ç‚¹ï¼Œ\n",
    "def find_best_split_point(data, feature):\n",
    "    # è·å–ç‰¹å¾çš„å”¯ä¸€å€¼å¹¶æ’åº\n",
    "    sorted_values = sorted(data[feature].unique())\n",
    "\n",
    "    # è®¡ç®—æœ€ä½³åˆ†å‰²ç‚¹å’Œæœ€ä½ Gini\n",
    "    def calculate_weighted_gini(split_point):\n",
    "        left_subset = data[data[feature] <= split_point]\n",
    "        right_subset = data[data[feature] > split_point]\n",
    "\n",
    "        gini_left = caculate_GINI(left_subset)\n",
    "        gini_right = caculate_GINI(right_subset)\n",
    "\n",
    "        weighted_gini = (len(left_subset) / len(data)) * gini_left + (len(right_subset) / len(data)) * gini_right\n",
    "        return weighted_gini\n",
    "\n",
    "    # ä½¿ç”¨minå‡½æ•°ç®€åŒ–è®¡ç®—å’Œæ¯”è¾ƒ\n",
    "    best_split_point, lowest_gini_index = min(\n",
    "        (( (sorted_values[i] + sorted_values[i + 1]) / 2, calculate_weighted_gini((sorted_values[i] + sorted_values[i + 1]) / 2) )\n",
    "         for i in range(len(sorted_values) - 1)),\n",
    "        key=lambda x: x[1]\n",
    "    )\n",
    "\n",
    "    return best_split_point, lowest_gini_index\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758999c7-5df2-4848-abd8-8243b8151fd0",
   "metadata": {},
   "source": [
    "### **CARTå†³ç­–æ ‘çš„æ„å»º**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57750700-f06e-4eea-a8ee-aebf2a1fbc1a",
   "metadata": {},
   "source": [
    "**é€‰æ‹©æœ€ä½³åˆ†å‰²ç‚¹**ï¼šé€šè¿‡è®¡ç®—æ‰€æœ‰ç‰¹å¾çš„ Gini å€¼æ¥é€‰æ‹©æœ€ä½³çš„åˆ†å‰²ç‰¹å¾ã€‚å¦‚æœæ˜¯è¿ç»­ç‰¹å¾ï¼Œåˆ™æ‰¾åˆ°æœ€ä½³çš„åˆ†å‰²ç‚¹ï¼›å¦‚æœæ˜¯ç¦»æ•£ç‰¹å¾ï¼Œåˆ™ç›´æ¥è®¡ç®— Gini æŒ‡æ•°ã€‚\n",
    "\n",
    "**è¿›è¡Œé€’å½’åœ°æ„å»ºå­æ ‘**ï¼šé€’å½’åœ°å¯¹å·¦å³å­é›†æˆ–ç¦»æ•£ç‰¹å¾çš„å­é›†è¿›è¡Œç›¸åŒçš„æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "92bbecfd-b008-4bfc-b593-0b057fe3040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CART_tree(data, features):\n",
    "    target = 'å¥½ç“œ'\n",
    "\n",
    "    # å¦‚æœæ‰€æœ‰ç›®æ ‡å€¼ç›¸åŒï¼Œè¿”å›è¯¥ç›®æ ‡å€¼ï¼ˆå¶èŠ‚ç‚¹ï¼‰\n",
    "    if data[target].nunique() == 1:\n",
    "        return data[target].iloc[0]\n",
    "\n",
    "    # å¦‚æœæ²¡æœ‰å‰©ä½™çš„ç‰¹å¾ç”¨äºåˆ†è£‚ï¼Œè¿”å›ç›®æ ‡åˆ—ä¸­æœ€å¸¸è§çš„ç±»åˆ«ï¼ˆä¼—æ•°ï¼‰\n",
    "    if not features:\n",
    "        return data[target].mode()[0]\n",
    "\n",
    "    # åˆå§‹åŒ–æœ€ä½³å±æ€§å’Œ Gini æŒ‡æ•°\n",
    "    best_feature, best_split_point, lowest_gini, is_continuous = None, None, float(\"inf\"), False\n",
    "\n",
    "    for feature in features:\n",
    "        if feature == 'å¯†åº¦':\n",
    "            # è¿ç»­ç‰¹å¾å¯»æ‰¾æœ€ä½³åˆ†å‰²ç‚¹\n",
    "            split_point, gini_value = find_best_split_point(data, feature)\n",
    "            if gini_value < lowest_gini:\n",
    "                best_feature, best_split_point, lowest_gini, is_continuous = feature, split_point, gini_value, True\n",
    "        else:\n",
    "            # ç¦»æ•£ç‰¹å¾ç›´æ¥è®¡ç®— Gini æŒ‡æ•°\n",
    "            gini_value = caculate_GINI_for_split(data, feature)\n",
    "            if gini_value < lowest_gini:\n",
    "                best_feature, lowest_gini, is_continuous = feature, gini_value, False\n",
    "\n",
    "    # æ„å»ºæ ‘çš„æ ¹èŠ‚ç‚¹\n",
    "    cart_tree = {best_feature: {}}\n",
    "\n",
    "    if is_continuous:\n",
    "        # å¤„ç†è¿ç»­ç‰¹å¾çš„åˆ†å‰²\n",
    "        left_subset, right_subset = data[data[best_feature] <= best_split_point], data[data[best_feature] > best_split_point]\n",
    "        cart_tree[best_feature][f'<= {best_split_point}'] = build_CART_tree(left_subset, features)\n",
    "        cart_tree[best_feature][f'> {best_split_point}'] = build_CART_tree(right_subset, features)\n",
    "    else:\n",
    "        # å¤„ç†ç¦»æ•£ç‰¹å¾çš„åˆ†å‰²\n",
    "        remaining_features = [f for f in features if f != best_feature]\n",
    "        for value in data[best_feature].unique():\n",
    "            subset = data[data[best_feature] == value]\n",
    "            cart_tree[best_feature][value] = build_CART_tree(subset, remaining_features) if not subset.empty else data[target].mode()[0]\n",
    "\n",
    "    return cart_tree\n",
    "\n",
    "# è¿‡æ»¤æ‰ç›®æ ‡åˆ—å’Œ 'ç¼–å·' åˆ—ï¼Œè·å–æ‰€æœ‰ç‰¹å¾\n",
    "features_cart = [col for col in train2_dataset.columns if col not in ['å¥½ç“œ', 'ç¼–å·']]\n",
    "\n",
    "\n",
    "# æ„å»º CART å†³ç­–æ ‘\n",
    "my_CART_tree = build_cart_tree(train2_dataset, features_cart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e2ff7a-84c2-452c-8715-8d09e5603695",
   "metadata": {},
   "source": [
    "#### è¿™æ—¶æ˜¯æˆ‘ä»¬æ„å»ºå‡ºæ¥çš„CARTå†³ç­–æ ‘åº”è¯¥å·²ç»åˆç†åœ°å¤„ç†å¯†åº¦è¿™ä¸ªè¿ç»­ç‰¹å¾äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6927ca1-4412-4212-abed-5aaf0064aa0d",
   "metadata": {},
   "source": [
    "### **ä½¿ç”¨CARTå†³ç­–æ ‘å¯¹æµ‹è¯•é›†dataset2è¿›è¡Œé¢„æµ‹å¹¶è®¡ç®—å‡†ç¡®åº¦**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1e95ea98-dae3-4d8b-965e-3994bd9fc980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARTå†³ç­–æ ‘æ–¹æ³•çš„å‡†ç¡®åº¦: 0.8\n"
     ]
    }
   ],
   "source": [
    "def calculate_cart_accuracy_and_predict(tree, test_data, target_column='å¥½ç“œ'):\n",
    "    correct_predictions = 0\n",
    "    no_branch_predictions = 0  # è®°å½•é¢„æµ‹ä¸º None çš„æ ·æœ¬æ•°\n",
    "\n",
    "    # éå†æµ‹è¯•æ•°æ®çš„æ¯ä¸€è¡Œï¼Œè¿›è¡Œé¢„æµ‹\n",
    "    for _, row in test_data.iterrows():\n",
    "        # é¢„æµ‹ä¸€ä¸ªæ ·æœ¬\n",
    "        def predict_cart(tree, sample):\n",
    "            # å¦‚æœå½“å‰èŠ‚ç‚¹æ˜¯å¶èŠ‚ç‚¹ï¼Œç›´æ¥è¿”å›é¢„æµ‹å€¼\n",
    "            if not isinstance(tree, dict):\n",
    "                return tree\n",
    "\n",
    "            # éå†å½“å‰èŠ‚ç‚¹çš„ç‰¹å¾åŠå…¶å­æ ‘\n",
    "            for feature, branches in tree.items():\n",
    "                if feature in sample:\n",
    "                    feature_value = sample[feature]\n",
    "\n",
    "                    # å¦‚æœæ˜¯è¿ç»­ç‰¹å¾çš„åˆ†å‰²ï¼Œå¤„ç† '<=' å’Œ '>'\n",
    "                    if isinstance(branches, dict):\n",
    "                        for branch_condition in branches.keys():\n",
    "                            # å¤„ç†è¿ç»­ç‰¹å¾çš„åˆ†æ”¯\n",
    "                            if branch_condition.startswith('<='): \n",
    "                                threshold = float(branch_condition[3:])  # é˜ˆå€¼æå–\n",
    "                                if feature_value <= threshold:\n",
    "                                    return predict_cart(branches[branch_condition], sample)\n",
    "                            elif branch_condition.startswith('>'):\n",
    "                                threshold = float(branch_condition[3:])  \n",
    "                                if feature_value > threshold:\n",
    "                                    return predict_cart(branches[branch_condition], sample)\n",
    "\n",
    "                    # å¦‚æœæ˜¯ç¦»æ•£ç‰¹å¾çš„åˆ†æ”¯ï¼Œç›´æ¥é€’å½’è®¿é—®å­æ ‘\n",
    "                    if feature_value in branches:\n",
    "                        return predict_cart(branches[feature_value], sample)\n",
    "\n",
    "            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„åˆ†æ”¯ï¼Œè¿”å› Noneï¼ˆæ— æ³•é¢„æµ‹ï¼‰\n",
    "            return None\n",
    "\n",
    "        # è¿›è¡Œé¢„æµ‹\n",
    "        predicted_label = predict_cart(tree, row)\n",
    "        actual_label = row[target_column]\n",
    "\n",
    "        # ç»Ÿè®¡é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬\n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions += 1\n",
    "        elif predicted_label is None:\n",
    "            no_branch_predictions += 1  # è®°å½•æ²¡æœ‰æ‰¾åˆ°åˆé€‚åˆ†æ”¯çš„æƒ…å†µ\n",
    "\n",
    "    # è®¡ç®—å¹¶è¿”å›å‡†ç¡®ç‡\n",
    "    accuracy = correct_predictions / len(test_data)\n",
    "    return accuracy\n",
    "\n",
    "# è®¡ç®—å¹¶æ‰“å°å‡†ç¡®ç‡\n",
    "cart_accuracy = calculate_cart_accuracy_and_predict(my_CART_tree, test2_dataset)\n",
    "print(f\"CARTå†³ç­–æ ‘æ–¹æ³•çš„å‡†ç¡®åº¦: {cart_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e836b9-cd8f-4f78-ae56-c9b5ad0976a7",
   "metadata": {},
   "source": [
    "#### å¯è§å…¶å‡†ç¡®åº¦è¾ƒé«˜ï¼Œæˆ‘è®¤ä¸ºåŸå› ä¸»è¦æ˜¯CARTåˆç†åœ°åˆ©ç”¨å¥½äº†è¿ç»­çš„å¯†åº¦ç‰¹å¾ä¿¡æ¯ï¼Œä»è€Œåšå‡ºâ€œé«˜æ˜â€çš„åˆ†ç±»å†³ç­–ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4b24b-4ced-4b02-b637-0799794ba83b",
   "metadata": {},
   "source": [
    "## ***é«˜çº§è¦æ±‚å®ç°ï¼ˆä½¿ç”¨ä»»æ„çš„å‰ªæç®—æ³•å¯¹æ„é€ çš„å†³ç­–æ ‘ï¼ˆåŸºæœ¬è¦æ±‚å’Œä¸­çº§è¦æ±‚æ„é€ çš„æ ‘ï¼‰è¿›è¡Œå‰ªæï¼‰***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28278ea4-650b-45bb-a100-325c4785abdd",
   "metadata": {},
   "source": [
    "**å‰ªæ**ï¼šå†³ç­–æ ‘å¾ˆå®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆç°è±¡ã€‚åŸå› åœ¨äºå­¦ä¹ æ—¶å®Œå…¨è€ƒè™‘çš„æ˜¯å¦‚ä½•æâ¾¼å¯¹è®­ç»ƒæ•°æ®çš„æ­£ç¡®åˆ†ç±»ä»â½½æ„å»ºå‡ºè¿‡äºå¤æ‚çš„å†³ç­–æ ‘ã€‚\n",
    "è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ç§°ä¸ºå‰ªæï¼Œå³å¯¹å·²ç”Ÿæˆçš„æ ‘è¿›è¡Œç®€åŒ–ã€‚å…·ä½“åœ°ï¼Œå°±æ˜¯ä»å·²ç”Ÿæˆçš„æ ‘ä¸Šè£å‰ªæ‰â¼€äº›å­æ ‘æˆ–å¶èŠ‚ç‚¹ï¼Œå¹¶å°†å…¶æ ¹èŠ‚ç‚¹æˆ–çˆ¶èŠ‚ç‚¹ä½œä¸ºæ–°çš„å¶èŠ‚ç‚¹ã€‚\n",
    "\n",
    "å†³ç­–æ ‘çš„å‰ªæåŸºæœ¬ç­–ç•¥æœ‰**é¢„å‰ªæ(Pre-Pruning)**å’Œ**åå‰ªæ(Post-Pruning)**ï¼š\n",
    "\n",
    "é¢„å‰ªæï¼šæ˜¯æ ¹æ®â¼€äº›åŸåˆ™ææ—©çš„åœæ­¢æ ‘å¢é•¿ï¼Œå¦‚æ ‘çš„æ·±åº¦è¾¾åˆ°ç”¨æˆ·æ‰€è¦çš„æ·±åº¦ã€èŠ‚ç‚¹ä¸­æ ·æœ¬ä¸ªæ•°å°‘äºç”¨æˆ·æŒ‡å®šä¸ªæ•°ã€ä¸çº¯åº¦æŒ‡æ ‡ä¸‹é™çš„å¹…åº¦å°äºç”¨æˆ·æŒ‡å®šçš„å¹…åº¦ç­‰ã€‚\n",
    "\n",
    "åå‰ªæï¼šæ˜¯é€šè¿‡åœ¨å®Œå…¨ç”Ÿé•¿çš„æ ‘ä¸Šå‰ªå»åˆ†æå®ç°çš„ï¼Œé€šè¿‡åˆ é™¤èŠ‚ç‚¹çš„åˆ†æ”¯æ¥å‰ªå»æ ‘èŠ‚ç‚¹ã€‚æ˜¯åœ¨ç”Ÿæˆå†³ç­–æ ‘ä¹‹åè‡ªåº•å‘ä¸Šçš„å¯¹æ ‘ä¸­æ‰€æœ‰çš„éå¶ç»“ç‚¹è¿›â¾é€ä¸€è€ƒå¯Ÿ ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd9137f-403e-4eac-a51f-ac3f933a1b93",
   "metadata": {},
   "source": [
    "å‰ªæçš„ä½œç”¨ï¼š\n",
    "\n",
    "é¿å…è¿‡æ‹Ÿåˆï¼šé€šè¿‡å‡å°‘æ ‘çš„å¤æ‚åº¦ï¼Œå‰ªææœ‰åŠ©äºæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n",
    "\n",
    "æé«˜æ¨¡å‹å¯è§£é‡Šæ€§ï¼šå‰ªæåçš„æ ‘ç»“æ„æ›´ç®€æ´ï¼Œå‡å°‘äº†å†—ä½™çš„åˆ†æ”¯ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb988a3-884e-4e1f-bfda-e1d1303b80c7",
   "metadata": {},
   "source": [
    "**è¿™é‡Œä¸¤ä¸ªå‰ªæå‡å¯¹åŸå‰ªææ ‘å®ç°åå‰ªæç®—æ³•**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d8139-73ab-4aa9-8c0a-771f52258706",
   "metadata": {},
   "source": [
    "### **å¯¹åŸºæœ¬è¦æ±‚å®ç°çš„å†³ç­–æ ‘çš„åå‰ªæ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffa295b-7097-4855-b8be-10796135526a",
   "metadata": {},
   "source": [
    "**å…³é”®å‡½æ•°è®¾è®¡è¯´æ˜**ï¼š\n",
    "\n",
    "post_pruningå‡½æ•°ï¼šè¿™æ˜¯å®ç°åå‰ªæçš„ä¸»è¦éƒ¨åˆ†ã€‚å®ƒé€’å½’éå†æ ‘çš„æ¯ä¸ªèŠ‚ç‚¹ï¼Œå¹¶å°è¯•å°†èŠ‚ç‚¹çš„å­æ ‘æ›¿æ¢ä¸ºå¶èŠ‚ç‚¹ï¼ˆå³èµ‹äºˆè¯¥èŠ‚ç‚¹æ•°æ®é›†ä¸­çš„å¤šæ•°ç±»æ ‡ç­¾ï¼‰ã€‚ç„¶åï¼Œè¯„ä¼°å‰ªæå‰åçš„å‡†ç¡®åº¦ï¼Œè‹¥å‰ªæåçš„å‡†ç¡®åº¦ä¸ä½äºåŸå‡†ç¡®åº¦ï¼Œåˆ™ä¿ç•™å‰ªæåçš„ç»“æ„ï¼Œå¦åˆ™æ¢å¤åŸçŠ¶ã€‚\n",
    "\n",
    "evaluate_accuracyå‡½æ•°ï¼šç”¨äºè®¡ç®—å‰ªæåçš„æ ‘åœ¨ç»™å®šæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡ã€‚å®ƒé€šè¿‡éå†æµ‹è¯•é›†ï¼Œå¯¹æ¯ä¸ªæ•°æ®ç‚¹è¿›è¡Œé¢„æµ‹å¹¶ä¸å®é™…æ ‡ç­¾æ¯”è¾ƒï¼Œä»è€Œè®¡ç®—å‡†ç¡®ç‡ã€‚\n",
    "\n",
    "dicision_tree_initå’Œdicision_tree_predictï¼šè¿™ä¸¤ä¸ªå‡½æ•°ç”¨äºæ„å»ºå†³ç­–æ ‘å’Œé¢„æµ‹è¿‡ç¨‹ï¼Œå’Œæˆ‘ä¹‹å‰çš„å®ç°éƒ½ä¸€æ ·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d984ec52-5ea8-445e-bf98-afba3135526e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy after pruning: 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "\n",
    "feature_dict = {\"è‰²æ³½\": [\"é’ç»¿\", \"ä¹Œé»‘\", \"æµ…ç™½\"],\n",
    "                \"æ ¹è’‚\": [\"èœ·ç¼©\", \"ç¨èœ·\", \"ç¡¬æŒº\"],\n",
    "                \"æ•²å£°\": [\"æµŠå“\", \"æ²‰é—·\", \"æ¸…è„†\"],\n",
    "                \"çº¹ç†\": [\"æ¸…æ™°\", \"ç¨ç³Š\", \"æ¨¡ç³Š\"]\n",
    "                }\n",
    "lable_list = [\"å¦\", \"æ˜¯\"]\n",
    "feature_list = [\"è‰²æ³½\", \"æ ¹è’‚\", \"æ•²å£°\", \"çº¹ç†\"]\n",
    "\n",
    "def load_txt(path):\n",
    "    ans = []\n",
    "    with codecs.open(path, \"r\", \"GBK\") as f:\n",
    "        line = f.readline()\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            d = line.rstrip(\"\\r\\n\").split(',')\n",
    "            re = []\n",
    "            re.append(int(d[0]))\n",
    "            re.append(feature_dict.get(\"è‰²æ³½\").index(d[1]))\n",
    "            re.append(feature_dict.get(\"æ ¹è’‚\").index(d[2]))\n",
    "            re.append(feature_dict.get(\"æ•²å£°\").index(d[3]))\n",
    "            re.append(feature_dict.get(\"çº¹ç†\").index(d[4]))\n",
    "            re.append(lable_list.index(d[-1]))\n",
    "            ans.append(np.array(re))\n",
    "            line = f.readline()\n",
    "    return np.array(ans)\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, attr, label, v):\n",
    "        self.attr = attr\n",
    "        self.label = label\n",
    "        self.attr_v = v\n",
    "        self.children = []\n",
    "\n",
    "def is_same_on_attr(X, attrs):\n",
    "    X_a = X[:, attrs]\n",
    "    target = X_a[0]\n",
    "    for r in range(X_a.shape[0]):\n",
    "        row = X_a[r]\n",
    "        if (row != target).any():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def ent(D):\n",
    "    s = 0\n",
    "    for k in set(D):\n",
    "        p_k = np.sum(np.where(D == k, 1, 0)) / np.shape(D)[0]\n",
    "        if p_k == 0:\n",
    "            continue\n",
    "        s += p_k * np.log2(p_k)\n",
    "    return -s\n",
    "\n",
    "def gain(X, Y, attr):\n",
    "    x_attr_col = X[:, attr]\n",
    "    ent_Dv = []\n",
    "    weight_Dv = []\n",
    "    for x_v in set(x_attr_col):\n",
    "        index_x_equal_v = np.where(x_attr_col == x_v)\n",
    "        y_x_equal_v = Y[index_x_equal_v]\n",
    "        ent_Dv.append(ent(y_x_equal_v))\n",
    "        weight_Dv.append(np.shape(y_x_equal_v)[0] / np.shape(Y)[0])\n",
    "    return ent(Y) - np.sum(np.array(ent_Dv) * np.array(weight_Dv))\n",
    "\n",
    "def dicision_tree_init(X, Y, attrs, root, purity_cal):\n",
    "    if len(set(Y)) == 1:\n",
    "        root.attr = np.pi\n",
    "        root.label = Y[0]\n",
    "        return None\n",
    "\n",
    "    if len(attrs) == 0 or is_same_on_attr(X, attrs):\n",
    "        root.attr = np.pi\n",
    "        root.label = np.argmax(np.bincount(Y))\n",
    "        return None\n",
    "\n",
    "    purity_attrs = []\n",
    "    for i, a in enumerate(attrs):\n",
    "        p = purity_cal(X, Y, a)\n",
    "        purity_attrs.append(p)\n",
    "\n",
    "    chosen_index = purity_attrs.index(max(purity_attrs))\n",
    "    chosen_attr = attrs[chosen_index]\n",
    "    root.attr = chosen_attr\n",
    "    root.label = np.pi\n",
    "    del attrs[chosen_index]\n",
    "\n",
    "    x_attr_col = X[:, chosen_attr]\n",
    "    for x_v in set(X[:, chosen_attr]):\n",
    "        n = Node(-1, -1, x_v)\n",
    "        root.children.append(n)\n",
    "        index_x_equal_v = np.where(x_attr_col == x_v)\n",
    "        X_x_equal_v = X[index_x_equal_v]\n",
    "        Y_x_equal_v = Y[index_x_equal_v]\n",
    "        dicision_tree_init(X_x_equal_v, Y_x_equal_v, attrs, n, purity_cal)\n",
    "\n",
    "def dicision_tree_predict(x, tree_root):\n",
    "    if tree_root.label != np.pi:\n",
    "        return tree_root.label\n",
    "\n",
    "    chose_attr = tree_root.attr\n",
    "    for child in tree_root.children:\n",
    "        if child.attr_v == x[chose_attr]:\n",
    "            return dicision_tree_predict(x, child)\n",
    "    return None\n",
    "\n",
    "def post_pruning(X, Y, node):\n",
    "    if node.label != np.pi:\n",
    "        return\n",
    "\n",
    "    for child in node.children:\n",
    "        post_pruning(X, Y, child)\n",
    "\n",
    "    original_accuracy = evaluate_accuracy(X, Y, node)\n",
    "    majority_class = np.argmax(np.bincount(Y))\n",
    "    node.children = []\n",
    "    node.label = majority_class\n",
    "    new_accuracy = evaluate_accuracy(X, Y, node)\n",
    "\n",
    "    if new_accuracy < original_accuracy:\n",
    "        node.label = majority_class\n",
    "        node.children = []\n",
    "\n",
    "def evaluate_accuracy(X, Y, node):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        predictions.append(dicision_tree_predict(x, node))\n",
    "    correct_predictions = sum(1 for y_true, y_pred in zip(Y, predictions) if y_true == y_pred)\n",
    "    total_predictions = len(Y)\n",
    "    return correct_predictions / total_predictions\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ans = load_txt(\"Watermelon-train1.csv\")\n",
    "    X_train = ans[:, 1: -1]\n",
    "    Y_train = ans[:, -1].astype(np.int64)\n",
    "    test_data = load_txt(\"Watermelon-test1.csv\")\n",
    "    X_test = test_data[:, 1:-1]\n",
    "    Y_test = test_data[:, -1].astype(np.int64)\n",
    "    \n",
    "    r = Node(-1, -1, -1)\n",
    "    attrs = [0, 1, 2, 3]\n",
    "\n",
    "    dicision_tree_init(X_train, Y_train, attrs, r, gain)\n",
    "\n",
    "    post_pruning(X_train, Y_train, r)\n",
    "\n",
    "    y_predict = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        x = X_test[i]\n",
    "        y_p = dicision_tree_predict(x, r)\n",
    "        y_predict.append(y_p)\n",
    "\n",
    "    correct_predictions = sum(1 for y_true, y_pred in zip(Y_test, y_predict) if y_true == y_pred)\n",
    "    total_predictions = len(Y_test)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print('accuracy after pruning:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453af75-0d8a-4c0a-a5f5-44621de3f221",
   "metadata": {},
   "source": [
    "#### å‘ç°å‰ªæåçš„ç²¾åº¦ä¸º0.5ï¼Œä¸å¦‚ä¹‹å‰çš„ä¸å‰ªæçš„å†³ç­–æ ‘ï¼Œç²¾åº¦å‡ºç°äº†ä¸‹é™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84952f5c-9c14-4479-b0b9-570041cc6188",
   "metadata": {},
   "source": [
    "### **å¯¹ä¸­çº§è¦æ±‚å®ç°çš„CARTå†³ç­–æ ‘çš„åå‰ªæ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945fac7a-14f4-476e-a434-ea585a5041dc",
   "metadata": {},
   "source": [
    "#### ä¸»è¦å‡½æ•°è®¾è®¡è¯´æ˜ï¼š\n",
    "\n",
    "prune_tree: è¿™æ˜¯åå‰ªæçš„ä¸»å‡½æ•°ï¼Œå®ƒé€’å½’éå†æ¯ä¸ªå­æ ‘ï¼Œå¦‚æœåœ¨æŸä¸ªèŠ‚ç‚¹å‰ªæåçš„è¯¯å·®ä¸å‰ªæå‰çš„è¯¯å·®å·®è·è¾ƒå°ï¼ˆå°äºä¸€ä¸ªé˜ˆå€¼ alphaï¼‰ï¼Œå°±å°†è¯¥èŠ‚ç‚¹å‰ªæä¸ºå¶èŠ‚ç‚¹ã€‚\n",
    "\n",
    "calculate_tree_error: è®¡ç®—æ ‘åœ¨éªŒè¯é›†ä¸Šçš„è¯¯å·®ï¼ˆå³é¢„æµ‹ä¸å‡†ç¡®çš„æ¯”ä¾‹ï¼‰ã€‚\n",
    "\n",
    "calculate_tree_error_after_pruning: è®¡ç®—å‰ªæåæ ‘çš„è¯¯å·®ã€‚å‰ªæåå³ç”¨å¶èŠ‚ç‚¹æ›¿ä»£æ ‘çš„æ‰€æœ‰å­æ ‘ã€‚\n",
    "\n",
    "get_leaf_value: ç”¨äºè·å–æ ‘çš„å¶èŠ‚ç‚¹å€¼ï¼Œå³æ ‘æ‰€æœ‰åˆ†æ”¯çš„æœ€ç»ˆé¢„æµ‹å€¼ã€‚\n",
    "\n",
    "alpha: æ§åˆ¶å‰ªæçš„ç¨‹åº¦ã€‚å¦‚æœ alpha ä¸ºè¾ƒå°å€¼ï¼Œå‰ªæä¼šæ›´åŠ æ¿€è¿›ï¼›è¾ƒå¤§å€¼æ—¶åˆ™ä¸ä¼šè½»æ˜“å‰ªæã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9f3cd868-740a-4d74-9c0d-1f80a5881b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_tree(tree, validation_data, target_column='å¥½ç“œ', alpha=0.01):\n",
    "    \"\"\"\n",
    "    åå‰ªæç®—æ³•ï¼Œé€’å½’åˆ é™¤ä¸é‡è¦çš„åˆ†æ”¯ï¼Œä»¥å‡å°‘è¿‡æ‹Ÿåˆã€‚\n",
    "    \"\"\"\n",
    "    # å¦‚æœæ ‘æ˜¯å¶å­èŠ‚ç‚¹ï¼Œåˆ™ç›´æ¥è¿”å›\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "\n",
    "    # éå†æ ‘çš„æ‰€æœ‰å­æ ‘\n",
    "    for feature, branches in tree.items():\n",
    "        for branch_condition, subtree in branches.items():\n",
    "            tree[feature][branch_condition] = prune_tree(subtree, validation_data, target_column, alpha)\n",
    "\n",
    "    # åœ¨å½“å‰èŠ‚ç‚¹å‰ªæï¼šè®¡ç®—å‰ªæå‰åçš„è¯¯å·®\n",
    "    error_before_pruning = calculate_tree_error(tree, validation_data, target_column)\n",
    "    error_after_pruning = calculate_tree_error_after_pruning(tree, validation_data, target_column)\n",
    "\n",
    "    # å¦‚æœå‰ªæåçš„è¯¯å·®ä¸æ¯”å‰ªæå‰å·®ï¼Œè¿›è¡Œå‰ªæ\n",
    "    if error_after_pruning <= error_before_pruning + alpha:\n",
    "        return get_leaf_value(tree)\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n",
    "def calculate_tree_error(tree, data, target_column='å¥½ç“œ'):\n",
    "    \"\"\"\n",
    "    è®¡ç®—å†³ç­–æ ‘åœ¨æ•°æ®é›†ä¸Šçš„è¯¯å·®\n",
    "    \"\"\"\n",
    "    predictions = data.apply(lambda row: predict_cart(tree, row), axis=1)\n",
    "    errors = predictions != data[target_column]\n",
    "    return errors.mean()  # è®¡ç®—é”™è¯¯ç‡\n",
    "\n",
    "\n",
    "def calculate_tree_error_after_pruning(tree, data, target_column='å¥½ç“œ'):\n",
    "    \"\"\"\n",
    "    è®¡ç®—å‰ªæåæ ‘çš„è¯¯å·®ï¼ˆå°†æ‰€æœ‰åˆ†æ”¯æ›¿æ¢ä¸ºå¶èŠ‚ç‚¹ï¼‰\n",
    "    \"\"\"\n",
    "    pruned_tree = get_leaf_value(tree)\n",
    "    predictions = data.apply(lambda row: predict_cart(pruned_tree, row), axis=1)\n",
    "    errors = predictions != data[target_column]\n",
    "    return errors.mean()\n",
    "\n",
    "\n",
    "def get_leaf_value(tree):\n",
    "    \"\"\"\n",
    "    è·å–æ ‘çš„å¶èŠ‚ç‚¹å€¼ï¼ˆå³ï¼Œæ‰€æœ‰åˆ†æ”¯çš„é¢„æµ‹ç»“æœï¼‰\n",
    "    \"\"\"\n",
    "    # å¦‚æœæ˜¯å¶å­èŠ‚ç‚¹ï¼Œç›´æ¥è¿”å›\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    for feature, branches in tree.items():\n",
    "        for branch_condition, subtree in branches.items():\n",
    "            return get_leaf_value(subtree)\n",
    "\n",
    "\n",
    "# æ„å»º CART å†³ç­–æ ‘\n",
    "features_cart = [col for col in train2_dataset.columns if col not in ['å¥½ç“œ', 'ç¼–å·']]\n",
    "\n",
    "# æ„å»ºåˆå§‹ CART å†³ç­–æ ‘\n",
    "my_CART_tree = build_CART_tree(train2_dataset, features_cart)\n",
    "\n",
    "# ä½¿ç”¨éªŒè¯é›†è¿›è¡Œå‰ªæ\n",
    "validation_data = train2_dataset  \n",
    "pruned_tree = prune_tree(my_CART_tree, validation_data, target_column='å¥½ç“œ', alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ca4ade5e-0f2b-4f89-b13d-f1fc441b685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARTå†³ç­–æ ‘æ–¹æ³•çš„å‡†ç¡®åº¦: 0.8\n"
     ]
    }
   ],
   "source": [
    "def calculate_cart_accuracy_and_predict(tree, test_data, target_column='å¥½ç“œ'):\n",
    "    correct_predictions = 0\n",
    "    no_branch_predictions = 0  # è®°å½•é¢„æµ‹ä¸º None çš„æ ·æœ¬æ•°\n",
    "\n",
    "    # éå†æµ‹è¯•æ•°æ®çš„æ¯ä¸€è¡Œï¼Œè¿›è¡Œé¢„æµ‹\n",
    "    for _, row in test_data.iterrows():\n",
    "        # é¢„æµ‹ä¸€ä¸ªæ ·æœ¬\n",
    "        def predict_cart(tree, sample):\n",
    "            # å¦‚æœå½“å‰èŠ‚ç‚¹æ˜¯å¶èŠ‚ç‚¹ï¼Œç›´æ¥è¿”å›é¢„æµ‹å€¼\n",
    "            if not isinstance(tree, dict):\n",
    "                return tree\n",
    "\n",
    "            # éå†å½“å‰èŠ‚ç‚¹çš„ç‰¹å¾åŠå…¶å­æ ‘\n",
    "            for feature, branches in tree.items():\n",
    "                if feature in sample:\n",
    "                    feature_value = sample[feature]\n",
    "\n",
    "                    # å¦‚æœæ˜¯è¿ç»­ç‰¹å¾çš„åˆ†å‰²ï¼Œå¤„ç† '<=' å’Œ '>'\n",
    "                    if isinstance(branches, dict):\n",
    "                        for branch_condition in branches.keys():\n",
    "                            # å¤„ç†è¿ç»­ç‰¹å¾çš„åˆ†æ”¯\n",
    "                            if branch_condition.startswith('<='): \n",
    "                                threshold = float(branch_condition[3:])  # é˜ˆå€¼æå–\n",
    "                                if feature_value <= threshold:\n",
    "                                    return predict_cart(branches[branch_condition], sample)\n",
    "                            elif branch_condition.startswith('>'):\n",
    "                                threshold = float(branch_condition[3:])  \n",
    "                                if feature_value > threshold:\n",
    "                                    return predict_cart(branches[branch_condition], sample)\n",
    "\n",
    "                    # å¦‚æœæ˜¯ç¦»æ•£ç‰¹å¾çš„åˆ†æ”¯ï¼Œç›´æ¥é€’å½’è®¿é—®å­æ ‘\n",
    "                    if feature_value in branches:\n",
    "                        return predict_cart(branches[feature_value], sample)\n",
    "\n",
    "            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„åˆ†æ”¯ï¼Œè¿”å› Noneï¼ˆæ— æ³•é¢„æµ‹ï¼‰\n",
    "            return None\n",
    "\n",
    "        # è¿›è¡Œé¢„æµ‹\n",
    "        predicted_label = predict_cart(tree, row)\n",
    "        actual_label = row[target_column]\n",
    "\n",
    "        # ç»Ÿè®¡é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬\n",
    "        if predicted_label == actual_label:\n",
    "            correct_predictions += 1\n",
    "        elif predicted_label is None:\n",
    "            no_branch_predictions += 1  # è®°å½•æ²¡æœ‰æ‰¾åˆ°åˆé€‚åˆ†æ”¯çš„æƒ…å†µ\n",
    "\n",
    "    # è®¡ç®—å¹¶è¿”å›å‡†ç¡®ç‡\n",
    "    accuracy = correct_predictions / len(test_data)\n",
    "    return accuracy\n",
    "\n",
    "# è®¡ç®—å¹¶æ‰“å°å‡†ç¡®ç‡\n",
    "cart_accuracy = calculate_cart_accuracy_and_predict(pruned_tree, test2_dataset)\n",
    "print(f\"CARTå†³ç­–æ ‘æ–¹æ³•çš„å‡†ç¡®åº¦: {cart_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd2dfa-58fd-4f81-9dcb-8714f52a8de0",
   "metadata": {},
   "source": [
    "#### å‘ç°å‰ªæåçš„ç²¾åº¦ä»ä¸º0.8ï¼Œåå‰ªææ²¡æœ‰ä½¿å¾—å†³ç­–æ ‘æ€§èƒ½æ›´ä½³ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57782b21-7872-41c9-8c43-5c806b39a374",
   "metadata": {},
   "source": [
    "### **åˆ†æç²¾åº¦ä¸‹é™æˆ–æ²¡æœ‰æé«˜çš„åŸå› **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09a03a-2456-4346-8a54-9f498b3cae40",
   "metadata": {},
   "source": [
    "**1. å‰ªæå¼•å…¥çš„è¿‡åº¦ç®€åŒ–**\n",
    "\n",
    "å‰ªæçš„ç›®æ ‡æ˜¯é€šè¿‡å‡å°‘æ ‘çš„å¤æ‚æ€§æ¥é¿å…è¿‡æ‹Ÿåˆã€‚ç„¶è€Œï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè¿‡åº¦å‰ªæä¼šå¯¼è‡´å†³ç­–æ ‘ç¼ºä¹è¶³å¤Ÿçš„è¡¨è¾¾èƒ½åŠ›ï¼Œä»è€Œé™ä½æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚\n",
    "\n",
    "ï¼ˆ1ï¼‰è¿‡åº¦å‰ªæï¼šå¦‚æœå‰ªæè¿‡æ—©æˆ–è¿‡åº¦ï¼Œå¯èƒ½å¯¼è‡´æ¨¡å‹æ— æ³•æ•æ‰åˆ°è®­ç»ƒæ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ã€‚å°¤å…¶æ˜¯åœ¨æ•°æ®é›†è¾ƒå¤æ‚æˆ–è€…ç‰¹å¾ä¹‹é—´çš„å…³è”æ€§è¾ƒå¼ºçš„æƒ…å†µä¸‹ï¼Œè¿‡åº¦ç®€åŒ–å¯èƒ½ä¼šå‡å°‘æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œä»è€Œå¯¼è‡´ç²¾åº¦ä¸‹é™ã€‚\n",
    "\n",
    "ï¼ˆ2ï¼‰å‰ªææ¡ä»¶ä¸åˆç†ï¼šé¢„å‰ªæå’Œåå‰ªæé€šå¸¸éƒ½æœ‰ä¸€äº›æ¡ä»¶ï¼Œä¾‹å¦‚èŠ‚ç‚¹æ ·æœ¬æ•°ä½äºæŸä¸ªé˜ˆå€¼ã€ä¿¡æ¯å¢ç›Šé™ä½ç­‰ã€‚å¦‚æœè¿™äº›æ¡ä»¶è®¾ç½®å¾—ä¸åˆç†ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹åœ¨æ ‘çš„æ—©æœŸæˆ–æ·±åº¦ä¸è¶³çš„æƒ…å†µä¸‹è¿›è¡Œå‰ªæï¼Œå¯¼è‡´åˆ†ç±»æ€§èƒ½é™ä½ã€‚\n",
    "\n",
    "**2. åå‰ªææ“ä½œå½±å“**\n",
    "\n",
    "\n",
    "ï¼ˆ1ï¼‰åå‰ªææ˜¯é€šè¿‡å®Œå…¨ç”Ÿæˆæ ‘åå†è¿›è¡Œçš„æ“ä½œã€‚å°½ç®¡è¿™ç§æ–¹æ³•å¯ä»¥é€šè¿‡é¿å…è¿‡æ—©åœæ­¢æ¥é˜²æ­¢æ¬ æ‹Ÿåˆï¼Œä½†å®ƒä¹Ÿå¯èƒ½å› ä¸ºè¿‡åº¦ä¿®å‰ªå»é™¤äº†ä¸€äº›é‡è¦çš„åˆ†æ”¯ï¼Œä»è€Œå¯¼è‡´æµ‹è¯•æ•°æ®é›†çš„ç²¾åº¦ä¸‹é™ã€‚\n",
    "\n",
    "ï¼ˆ2ï¼‰å‰ªææ­¥éª¤ï¼šåå‰ªæé€šå¸¸æ˜¯è‡ªåº•å‘ä¸Šçš„æ“ä½œï¼Œä¼šä»å¶å­èŠ‚ç‚¹é€æ­¥å›æº¯ï¼Œæ£€æŸ¥æ¯ä¸ªå†…éƒ¨èŠ‚ç‚¹æ˜¯å¦åº”è¯¥å‰ªå»ã€‚åœ¨è¿›è¡Œåå‰ªææ—¶ï¼Œå¦‚æœå‰ªå»çš„åˆ†æ”¯å®é™…åœ¨æµ‹è¯•é›†ä¸Šå…·æœ‰è¾ƒé«˜çš„åˆ†ç±»ç²¾åº¦ï¼Œç²¾åº¦å¯èƒ½ä¼šæ˜¾è‘—ä¸‹é™ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
